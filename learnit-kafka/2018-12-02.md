# 2018-12-02 5장 카프카 컨슈머

스터디 참여한 다른 분의 자료를 markdown 형태로만 변환 함 [원문](https://docs.google.com/document/d/1877qotTTDqYfS4J_7U2x5mIFHQ7o_l8kuFWap8d2jec/edit)

## 오프셋 이란

> Offset란? 파티션안에 데이터 위치를 유니크한 숫자로 표시한 것 구버전(0.9이전) 의 카프카에서는 오프셋정보를  
주키퍼의 지노드에 저장하는 방식으로 지원하다가 0.9 버전 이후부터는 카프카의 토픽에 저장 하는 방식으로 변경 (성능 등 의 문제로)

## Python을 이용한 Consumer 개발 lib 설치 하기

```bash
  > rpm -Uvh https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm && yum install python-pip -y
  > pip install --upgrade pip && pip install --upgrade setuptools && pip install kafka-python
```

```python
  from kafka import KafkaConsumer
  consumer = KafkaConsumer("test.topic", group_id="test-consumer1", bootstrap_servers="kafka1:9092,kafka2:9092,kafka3:9092",
                        enable_auto_commit=True, auto_offset_reset="earliest")
  for message in consumer:
        print "Topic %s, partition: %d, offset: %d, key: %s, value: %s" % \
                (message.topic, message.partition, message.offset, message.key, message.value.decode("utf-8"))
```

### 옵션 설명

- group_id: consumer의 group id
- enable_auto_commit: 자동으로 커밋을 하겠다 (기본 5초 간격)
- auto_offset_reset: 초기 오프셋이 없거나 현재 오프셋이 더이상 존재 하지 않는 경우 다음 옵션으로 오프셋을 맞춤
- earliest: 가장 초기의 오프셋 값으로 설정
- latest: 가장 마지막의 오프셋값으로 설정
- none: 이전 오프셋 값을 찾지 못하면 에러

## 카프카 쉘 명령어

- 토픽 전체 리스트 확인

```bash
  ./bin/kafka-topics.sh --zookeeper kafka1:2181,kafka2:2181,kafka3:2181/jhc --list
```

- 토픽 정보 확인.

```bash
  ./bin/kafka-topics.sh --zookeeper kafka1:2181,kafka2:2181,kafka3:2181/jhc --topic test.topic --describe
```

- consumer 그룹 정보 확인

```bash
  ./bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092 --list
```

- LAG 정보 확인

```bash
  ./bin/kafka-consumer-groups.sh --bootstrap-server kafka1:9092,kafka2:9093,kafka3:9094 --group consumer_group --describe
```

- 토픽의 파티션수 변경

```bash
./bin/kafka-topics.sh --zookeeper kafka1:2181,kafka2:2181,kafka3:2181 --alter --topic test.topic --partitions 4
```

- 토픽 생성

```bash
  bin/kafka-topics.sh --create --zookeeper kafka1:2181,kafka2:2181,kafka3:2181/jhc --replication-factor 1 --partitions 5 --topic test.topic
```

- 토픽 삭제

```bash
  bin/kafka-topics.sh --delete --zookeeper kafka1:2181,kafka2:2181,kafka3:2181/jhc  --topic test.topic
```

- 테스트 producer

```bash
  bin/kafka-producer-perf-test.sh --topic test.topic --num-records 10 --record-size 100 --throughput 100 --producer-props acks=1 bootstrap.servers=kafka1:9092,kafka2:9092,kafka3:9092
```

- 테스트 consumer

```bash
  bin/kafka-consumer-perf-test.sh --topic test.topic --zookeeper kafka1:2181,kafka2:2181,kafka3:2181/jhc --messages 10 --threads 1 
```

- 토픽으로 부터 메시지 가져오기

```bash
  ./bin/kafka-console-consumer.sh --bootstrap-server kafka1:9092,kafka2:9092,kafka3:9092 --topic test.topic --from-beginning
```

> --from-beginning : 토픽의 처음부터 메시지를 가져옴

## 파티션과 메시지 순서

파티션을 다수로 구성한 상태에서 메시지의 순서는 보장할 수 없다. (각각의 파티션에서의 메시지는 순서가 보장됨)
순차적으로 가져오고싶다면 파티션을 하나만 사용해야한다.

## 컨슈머 그룹

컨슈머 그룹 안에서 컨슈머들은 메시지를 가져오고 있는 토픽의 파티션에 대해 소유권을 공유
프로듀서가 넣는 데이터 양 에 비해 컨슈머가 가져가는게 적다고 가정한다면 컨슈머를 늘려줘야한다. (당연한 소리)  
consumer group 안에 consumer를 추가할수 있다.  
consumer를 추가하면 내부에서 파티션의 소유권이 변경되는 리벨런스 가 발생하게 된다. ( 리벨런스 발생 시 일시적으로 토픽에서 메시지를 가져올수 없다)  
파티션 하나에 컨슈머 하나 N:1 (파티션 하나에는 무조건 컨슈머 하나를 지정할수 있다. 컨슈머 하나에는 파티션을 여러개 지정할 수 있음)  
효율적으로 사용하기 위해서는 파티션과 컨슈머 개수를 절반이나 동일하게 가져가는게 좋다고 함  

[참조](https://www.popit.kr/kafka-consumer-group/)
컨슈머 그룹마다 오프셋 관리를 따로 함, 메시지를 가져가도 삭제하지않기 때문에 여러팀에서 데이터를 가져갈 수 있다.  
컨슈머가 그룹 코디네이터에게 하트비트를 일정시간 보내지 않으면 컨슈머 그룹의 리벨런스가 일어남. server.properties >session.timeout.ms 옵션 (기본값 10초)  
리벨런스가 일어난 후 각각의 컨슈머는 새로운 파티션할당되고 해당 파티션에 대해 가장 최근 커밋된 오프셋을 읽고 그 이후 부터 메시지들을 가져오기 시작함.  
커밋된 오프셋이 컨슈머가 실제 마지막으로 처리한 오프셋보다 작으면 중복데이터 발생, 크면 누락  

- 자동 커밋
> enable.auto.commit=true 로 설정하면 5초마다 컨슈머는 poll()을 호출하여 가장 마지막 오프셋을 커밋함. 5초는 기본값,  
auto.commit.interval.ms을 통하여 조정이 가능하다  
오토커밋이 되기전 (기본5초) 3초가 지나 리벨런싱이 일어나면 어떻게 되는가?  
마지막 오프셋 이후의 데이터는 중복으로 다시한번 가져가게 된다.  
오토 커밋 시간을 줄이는것으로 해당 증상을 완화 시킬수는있지만. 완벽하게 제거하는것은 불가능 하다.  

- 수동 커밋
> 메시지 처리가 완료될때 커밋하는 방식 
예를들어 컨슈머가 데이터를 읽어 데이터베이스에 넣는다고 생각하면 
데이터 베이스에서 데이터를 저장하고 커밋하는식으로 소스코드를 작성

- 특정 파티션 할당 
> 특정한 파티션을 할당해 메시지를 가져올 수 있다. 

- 특정 오프셋부터 메시지를 가져오기 
> 특정 오프셋으로부터 메시지를 가져올 수 있다.

## 참고 사항

[압축률 및 테스트](https://www.slideshare.net/freepsw/apache-kafka-performancethroughput-without-data-loss-and-guaranteeing-data-order)
[링크드 인에서 테스트한 벤치마킹](https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines)